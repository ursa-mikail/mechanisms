# Oblivious Transfer 

ğŸ§  Scenario: Private Model Access
Suppose a user (Bob) wants to query a machine learning model (held by Alice) but doesn't want to reveal which part of the model they are querying. Meanwhile, the model owner (Alice) wants to ensure the user only learns the result of that single query, and not the whole model.

**Example Use Case**:
Imagine a hospital wants to query a cloud-hosted AI model to predict disease risk from genomic markers, but doesn't want to expose which genetic marker theyâ€™re querying due to patient privacy.

## 1-out-of-2

ğŸ” How this Code Enables That:
- Alice prepares encrypted responses for all possible queries.
- Bob chooses 1 index c (e.g., corresponding to a neural net weight or a genomic marker) and engages in OT using this protocol.

- Using the OT process:
	- Bob can decrypt only the response corresponding to the chosen query.
	- Alice does not know which query Bob made.
- This keeps both model privacy (Aliceâ€™s weights are hidden) and query privacy (Bobâ€™s interest is private).

**Caveat(s)**
- Alice must remember what Bob had asked for, the pairs or N clusters of request, must not repeat. Hence, Bob has to segment the request, and only able to obtain 1 of each sessional request. 

| **Need**                             | **This Protocol Provides**                  |
| ------------------------------------ | ------------------------------------------- |
| Secure access to proprietary models  | Only selected parts of model are revealed   |
| Privacy-preserving inference         | User query remains hidden from the model    |
| Fairness in federated learning       | Prevents data leakage during local training |
| Confidential multi-party computation | Key in private ML collaboration             |

ğŸš€ Extensions in Practice:
- Integrate with Secure Multi-Party Computation (SMPC) or Homomorphic Encryption frameworks like Microsoft SEAL or TF Encrypted.
- Used in federated learning settings with TensorFlow Federated or PySyft.
- Can support Zero-Knowledge Proof-based model access.

âœ… AI/ML Use Case Scenario:
Alice owns a model and produces 2 possible outputs (e.g., prediction for disease A and prediction for disease B).

Bob wants only 1 of these outputs privately.

Using 1-out-of-2 Oblivious Transfer, Bob decrypts only 1 result, and Alice doesn't know which.

![ot_1_of_2](ot_1_of_2.png)

ğŸ§ª Example Run:
- Alice generates predictions:
	- m0 = "Disease A risk 10%"
	- m1 = "Disease B risk 72%"
- Bob inputs 1 â†’ only gets prediction for Disease B.
- Alice never learns Bob's choice.

ğŸ§  Future Enhancements:
Scale to 1-out-of-n OT (more than two outputs).

Integrate this into a secure inference service using Flask + PyTorch/TF.

Add ZK Proofs to verify the query was valid (optional, for higher security).

## 1-out-of-N

Scaling to 1-out-of-n Oblivious Transfer (OT) means Bob can privately choose 1 of many model outputs (e.g., $$\ ğ‘š_0 , ğ‘š_1 , â€¦ , ğ‘š_{ğ‘› âˆ’ 1}â€‹ \$$ ), and learn only that 1, without Alice knowing which, and without Bob learning the others.

ğŸ” Approach: 1-out-of-n OT via Diffie-Hellman-style keys
Extend the current OT scheme by using:
- A shared group with prime modulus p and generator g.
- Alice computes and encrypts all n messages, using unique symmetric keys that depend on her secret and Bob's input.
- Bob can compute the decryption key for only 1 message index ğ‘–.

## âš™ï¸ Key Idea: 
Simulate a simplified version of 1-out-of-n OT: 
- Bob sends ğ‘‡ = $$\ ğ‘”^ğ‘Ÿ â‹… â„_ğ‘– \$$ â€‹ where $$\ â„_ğ‘– = ğ‘”^{ğ‘˜_ğ‘–} \$$ â€‹ for a public list of values generated by Alice. 
- Alice encrypts $$\  ğ‘š_ğ‘– â€‹ \$$ with key derived from $$\ ğ‘‡^ğ‘ \$$. 
- Bob computes $$\ ( ğ‘”^ğ‘Ÿ ) ^ğ‘ = ğ‘” ^{ğ‘ğ‘Ÿ} \$$  and recovers key only for the index he selected. This version assumes a semi-honest model (no malicious actors).

| Role      | Action                                                           |
| --------- | ---------------------------------------------------------------- |
| **Alice** | Encrypts all model outputs using unique keys                     |
| **Bob**   | Privately chooses one index, constructs a smart public value $T$ |
| **Alice** | Encrypts messages using derived keys from $T$                    |
| **Bob**   | Decrypts only his selected message using shared secret $g^{ar}$  |

ğŸ§ª Applications:
- Privacy-preserving model APIs (e.g. only 1 feature/prediction retrieved)
- Federated learning where clients selectively pull model updates
- Secure inference in healthcare and finance


